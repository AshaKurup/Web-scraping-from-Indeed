{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB SCRAPING FROM INDEED USING BEAUTIFUL SOUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LOAD LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                                             # For reading data\n",
    "from bs4 import BeautifulSoup                                   # For scraping websites\n",
    "import requests                                                 # To get website\n",
    "import time                                                     # To make sure that system doesnt hang due to large data\n",
    "import csv                                                      # to create csv file\n",
    "import os                                                       # to check status of specific path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = requests.get(\"https://au.indeed.com/jobs?q=data%20science&l&advn=6804915630397510\").text\n",
    "soup = BeautifulSoup(url, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. EXTRACT DATA\n",
    "In every page, 'Job Title','Company', 'Location', 'Job Details', 'Salary' are extracted for each job. HTML tags are used for\n",
    "extraction. NA's are used if the field is missing to prevent crashing. Here 975 job details are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [0,10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290]\n",
    "\n",
    "with open('C:/Users/Asha Sanjeev Kurup/Desktop/Portfolio/Data_science_jobs.csv', 'a', encoding='utf-8', newline='') as f_output:\n",
    "    csv_print = csv.writer(f_output)\n",
    "    file_is_empty = os.stat('C:/Users/Asha Sanjeev Kurup/Desktop/Portfolio/Data_science_jobs.csv').st_size == 0\n",
    "    if file_is_empty:\n",
    "        csv_print.writerow(['Job Title','Company', 'Location', 'Job Details', 'Salary'])\n",
    "        \n",
    "    for page in pages:\n",
    "        url = requests.get(\"https://au.indeed.com/jobs?q=data+science&start={}\".format(page)).text\n",
    "        soup = BeautifulSoup(url, 'lxml')\n",
    "\n",
    "        for jobs in soup.find_all(class_='result'):\n",
    "            try:\n",
    "                title = jobs.find('div', class_='title').text.strip()\n",
    "            except Exception as e:\n",
    "                title = None\n",
    "            \n",
    "\n",
    "            try:\n",
    "                company = jobs.find('span',class_='company').text.strip()\n",
    "            except Exception as e:\n",
    "                company = None\n",
    "            \n",
    "\n",
    "            try:\n",
    "                location = jobs.find('div',class_=\"location accessible-contrast-color-location\").text.strip()\n",
    "            except Exception as e:\n",
    "                location = None\n",
    "            \n",
    "\n",
    "            try:\n",
    "                job_details = jobs.find('div', class_='summary').text.strip()\n",
    "            except Exception as e:\n",
    "                job_details = None\n",
    "            \n",
    "\n",
    "            try:\n",
    "                salary = jobs.find('span', class_=\"salaryText\").text.strip()\n",
    "            except Exception as e:\n",
    "                salary = None\n",
    "            \n",
    "            \n",
    "            csv_print.writerow([title,company,location,job_details,salary])\n",
    "\n",
    "            \n",
    "\n",
    "            time.sleep(2)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. DISPLAY DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Details</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Xilinx Field Applications Engineers</td>\n",
       "      <td>Avnet</td>\n",
       "      <td>Melbourne Eastern Suburbs VIC</td>\n",
       "      <td>Bachelor or Masters inElectronic Engineering o...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cropping manager</td>\n",
       "      <td>D &amp; J Rich</td>\n",
       "      <td>Bordertown SA</td>\n",
       "      <td>Gather relevant data and maintain records of c...</td>\n",
       "      <td>$55,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medical Administration - Reports / Monitors</td>\n",
       "      <td>Heartscope Victoria</td>\n",
       "      <td>Melbourne Eastern Suburbs VIC</td>\n",
       "      <td>Downloading data from monitors (Sleep study, b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Hello Sunday Morning</td>\n",
       "      <td>Sydney NSW</td>\n",
       "      <td>Classify and reclassify highly sensitive data;...</td>\n",
       "      <td>$70,000 - $85,000 a year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Rio Tinto</td>\n",
       "      <td>Perth WA</td>\n",
       "      <td>A Mining/Processing/Marketing/Data Science or ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Job Title               Company  \\\n",
       "0          Xilinx Field Applications Engineers                 Avnet   \n",
       "1                             Cropping manager            D & J Rich   \n",
       "2  Medical Administration - Reports / Monitors   Heartscope Victoria   \n",
       "3                                 Data Analyst  Hello Sunday Morning   \n",
       "4                                 Data Analyst             Rio Tinto   \n",
       "\n",
       "                        Location  \\\n",
       "0  Melbourne Eastern Suburbs VIC   \n",
       "1                  Bordertown SA   \n",
       "2  Melbourne Eastern Suburbs VIC   \n",
       "3                     Sydney NSW   \n",
       "4                       Perth WA   \n",
       "\n",
       "                                         Job Details                    Salary  \n",
       "0  Bachelor or Masters inElectronic Engineering o...                       NaN  \n",
       "1  Gather relevant data and maintain records of c...            $55,000 a year  \n",
       "2  Downloading data from monitors (Sleep study, b...                       NaN  \n",
       "3  Classify and reclassify highly sensitive data;...  $70,000 - $85,000 a year  \n",
       "4  A Mining/Processing/Marketing/Data Science or ...                       NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data = pd.read_csv(\"Data_science_jobs.csv\")\n",
    "job_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(975, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
